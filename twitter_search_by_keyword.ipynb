{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트위터 검색 크롤러\n",
    "\n",
    "### 참조\n",
    "- [Python, Selenium 사용법](https://wordbe.tistory.com/entry/%ED%81%AC%EB%A1%A4%EB%A7%81-Python-Selenium-%EC%82%AC%EC%9A%A9%EB%B2%95) \n",
    "- [파이썬을 이용한 Twitter 크롤링](https://medium.com/@whj2013123218/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-twitter-%ED%81%AC%EB%A1%A4%EB%A7%81-576f7b098daf)\n",
    "- [인프런 - Twitter CSS 참고](https://www.inflearn.com/questions/42753)\n",
    "- [CSS Selector를 사용한 크롤링](https://www.fun-coding.org/crawl_basic4.html)\n",
    "\n",
    "이 블로그들을 기반으로 응용해 보았다! \n",
    "\n",
    "> selenium, BeautifulSoup, chromedriver 설치 후 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /opt/anaconda3/lib/python3.8/site-packages (3.141.0)\r\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.8/site-packages (from selenium) (1.25.9)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium\n",
    "! pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "크롬으로 keyword, 기간을 지정해서 txt파일로 반환하는 코드\n",
    "\n",
    "-> 개선해야될 부분\n",
    "- 유저 단위로 나누기 (ID도 지우기)\n",
    "- 좋아요, 리트윗 등 숫자 지우기\n",
    "- 광고 거르고 싶다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10 19\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10 23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10 27\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0afd3e50d7ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"window.scrollTo(0, document.body.scrollHeight);\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mnewHeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"return document.body.scrollHeight\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "# 크롬드라이버 저장 경로\n",
    "chromedriver = '<로컬 경로 입력>'\n",
    "\n",
    "# 검색할 날짜 list로 설정 [month, day] 형태\n",
    "# 예) match = [[10, 19], [10, 23], [10, 27]]\n",
    "match = [[0, 0], [0, 0]]\n",
    "\n",
    "# 검색 키워드 지정\n",
    "keyword = \"<키워드>\"\n",
    "\n",
    "# 확인할 기간\n",
    "interval = <기간>\n",
    "\n",
    "for m in match:\n",
    "    # 크롬 드라이버 연결 (중요!)\n",
    "    # browser을 새로 열 때마다 새로 연결해야한다! \n",
    "    browser = webdriver.Chrome(chromedriver)\n",
    "    \n",
    "    # 검색 기간(날짜) 설정\n",
    "    startdate = dt.date(year=2020, month=m[0], day=m[1])\n",
    "    untildate = startdate + dt.timedelta(days=1) # 하루하루의 결과를 출력하기 위한 중간변수\n",
    "    enddate = startdate + dt.timedelta(days=interval)\n",
    "\n",
    "    # 크롤링 결과 txt파일로 저장 <파일명_월_일.txt>\n",
    "    # 날짜별 정렬을 위해 자리수를 2자리로 맞춰준다\n",
    "    filename = \"<파일명>_\" + str('{0:0>2}'.format(m[0])) + '_' + str('{0:0>2}'.format(m[1])) + \".txt\"\n",
    "    file = open(filename, 'w')\n",
    "\n",
    "    while not enddate == startdate:\n",
    "        # url에서 until + <날짜> 는 결과에 포함되지 않는다.\n",
    "        url='https://twitter.com/search?q='+keyword+'%20since%3A'+str(startdate)+'%20until%3A'+str(untildate)+'&amp;amp;amp;amp;amp;amp;lang=eg'\n",
    "\n",
    "        # 크롬 실행\n",
    "        browser.get(url)\n",
    "        html = browser.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # 로딩 기다림\n",
    "        time.sleep(3)\n",
    "        \n",
    "        lastHeight = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        \n",
    "        while True:\n",
    "\n",
    "            tweet = soup.select('div#react-root main section article span')\n",
    "\n",
    "            if len(tweet) > 12: # 12 필요없는 데이터로 취급하고 저장하지 않는다.\n",
    "                for x in range(len(tweet)):\n",
    "                    file.write(tweet[x].get_text())\n",
    "                file.write('\\n')\n",
    "\n",
    "            # 스크롤 내리는 코드 (트위터 특성상 스크롤을 내려야 한다)\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(1)\n",
    "\n",
    "            newHeight = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "            if newHeight != lastHeight:\n",
    "                html = browser.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "            else:\n",
    "                startdate=untildate\n",
    "                untildate += dt.timedelta(days=1)\n",
    "                break\n",
    "            lastHeight = newHeight\n",
    "    \n",
    "    file.write('Total Count in '+ str(match[i][0]) + '/' + str(match[i][1]) + ' : '+ str(count))\n",
    "    file.close()\n",
    "    print(match[i][0],  match[i][1])\n",
    "\n",
    "    browser.quit()\n",
    "    time.sleep(3)\n",
    "    \n",
    "print('All Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
